<!DOCTYPE html><html class="theme-next gemini use-motion" lang="zh-Hans"><head><meta name="generator" content="Hexo 3.9.0"><meta charset="UTF-8"><meta http-equiv="X-UA-Compatible" content="IE=edge"><meta name="viewport" content="width=device-width,initial-scale=1,maximum-scale=1"><meta name="theme-color" content="#222"><meta http-equiv="Cache-Control" content="no-transform"><meta http-equiv="Cache-Control" content="no-siteapp"><link href="/lib/fancybox/source/jquery.fancybox.css?v=2.1.5" rel="stylesheet" type="text/css"><link href="/lib/font-awesome/css/font-awesome.min.css?v=4.6.2" rel="stylesheet" type="text/css"><link href="/css/main.css?v=5.1.4" rel="stylesheet" type="text/css"><link rel="apple-touch-icon" sizes="180x180" href="/images/apple-touch-icon-next.png?v=5.1.4"><link rel="icon" type="image/png" sizes="32x32" href="/images/favicon-32x32-next.png?v=5.1.4"><link rel="icon" type="image/png" sizes="16x16" href="/images/favicon-16x16-next.png?v=5.1.4"><link rel="mask-icon" href="/images/logo.svg?v=5.1.4" color="#222"><meta name="keywords" content="书本总结,机器学习,"><meta name="description" content="第二章 第一个完整的机器学习项目假设你是一个房地产公司的数据科学家，你的任务是使用加利福尼亚人口普查数据建立该州房价模型。该数据包括加利福尼亚州每个地区的人口，收入中位数和房价中位数等指标。模型应该从这些数据中学习，并能够根据所有其他指标来预测任何地区的房价中位数。完成一机器学习项目一般包含八个步骤：分析问题，问题的输入输出准备数据探索数据获得想法准备数据以更好地将潜在数据模式暴露给机器学习算法探"><meta name="keywords" content="书本总结,机器学习"><meta property="og:type" content="article"><meta property="og:title" content="Hands-on Machine Learning第二章"><meta property="og:url" content="http://tinymd.github.io/post/8212f318.html"><meta property="og:site_name" content="Tiny‘s blog"><meta property="og:description" content="第二章 第一个完整的机器学习项目假设你是一个房地产公司的数据科学家，你的任务是使用加利福尼亚人口普查数据建立该州房价模型。该数据包括加利福尼亚州每个地区的人口，收入中位数和房价中位数等指标。模型应该从这些数据中学习，并能够根据所有其他指标来预测任何地区的房价中位数。完成一机器学习项目一般包含八个步骤：分析问题，问题的输入输出准备数据探索数据获得想法准备数据以更好地将潜在数据模式暴露给机器学习算法探"><meta property="og:locale" content="zh-Hans"><meta property="og:image" content="https://myblogdata-1300038172.cos.ap-shanghai.myqcloud.com/images/hands_on_ml_tf/2_1.png"><meta property="og:image" content="https://myblogdata-1300038172.cos.ap-shanghai.myqcloud.com/images/hands_on_ml_tf/2_2.png"><meta property="og:image" content="https://myblogdata-1300038172.cos.ap-shanghai.myqcloud.com/images/hands_on_ml_tf/2_3.png"><meta property="og:image" content="https://myblogdata-1300038172.cos.ap-shanghai.myqcloud.com/images/hands_on_ml_tf/2_4.png"><meta property="og:image" content="https://myblogdata-1300038172.cos.ap-shanghai.myqcloud.com/images/hands_on_ml_tf/2_5.png"><meta property="og:image" content="https://myblogdata-1300038172.cos.ap-shanghai.myqcloud.com/images/hands_on_ml_tf/2_6.png"><meta property="og:image" content="https://myblogdata-1300038172.cos.ap-shanghai.myqcloud.com/images/hands_on_ml_tf/2_7.png"><meta property="og:image" content="https://myblogdata-1300038172.cos.ap-shanghai.myqcloud.com/images/hands_on_ml_tf/2_8.png"><meta property="og:image" content="https://myblogdata-1300038172.cos.ap-shanghai.myqcloud.com/images/hands_on_ml_tf/2_9.png"><meta property="og:image" content="https://myblogdata-1300038172.cos.ap-shanghai.myqcloud.com/images/hands_on_ml_tf/2_10.png"><meta property="og:updated_time" content="2020-02-26T12:14:31.905Z"><meta name="twitter:card" content="summary"><meta name="twitter:title" content="Hands-on Machine Learning第二章"><meta name="twitter:description" content="第二章 第一个完整的机器学习项目假设你是一个房地产公司的数据科学家，你的任务是使用加利福尼亚人口普查数据建立该州房价模型。该数据包括加利福尼亚州每个地区的人口，收入中位数和房价中位数等指标。模型应该从这些数据中学习，并能够根据所有其他指标来预测任何地区的房价中位数。完成一机器学习项目一般包含八个步骤：分析问题，问题的输入输出准备数据探索数据获得想法准备数据以更好地将潜在数据模式暴露给机器学习算法探"><meta name="twitter:image" content="https://myblogdata-1300038172.cos.ap-shanghai.myqcloud.com/images/hands_on_ml_tf/2_1.png"><script type="text/javascript" id="hexo.configurations">var NexT=window.NexT||{},CONFIG={root:"/",scheme:"Gemini",version:"5.1.4",sidebar:{position:"left",display:"post",offset:12,b2t:!1,scrollpercent:!1,onmobile:!1},fancybox:!0,tabs:!0,motion:{enable:!0,async:!1,transition:{post_block:"fadeIn",post_header:"slideDownIn",post_body:"slideDownIn",coll_header:"slideLeftIn",sidebar:"slideUpIn"}},duoshuo:{userId:"0",author:"博主"},algolia:{applicationID:"",apiKey:"",indexName:"",hits:{per_page:10},labels:{input_placeholder:"Search for Posts",hits_empty:"We didn't find any results for the search: ${query}",hits_stats:"${hits} results found in ${time} ms"}}}</script><link rel="canonical" href="http://tinymd.github.io/post/8212f318.html"><title>Hands-on Machine Learning第二章 | Tiny‘s blog</title></head><body itemscope itemtype="http://schema.org/WebPage" lang="zh-Hans"><div class="container sidebar-position-left page-post-detail"><div class="headband"></div><header id="header" class="header" itemscope itemtype="http://schema.org/WPHeader"><div class="header-inner"><div class="site-brand-wrapper"><div class="site-meta"><div class="custom-logo-site-title"><a href="/" class="brand" rel="start"><span class="logo-line-before"><i></i></span> <span class="site-title">Tiny‘s blog</span> <span class="logo-line-after"><i></i></span></a></div><p class="site-subtitle"></p></div><div class="site-nav-toggle"><button><span class="btn-bar"></span> <span class="btn-bar"></span> <span class="btn-bar"></span></button></div></div><nav class="site-nav"><ul id="menu" class="menu"><li class="menu-item menu-item-home"><a href="/" rel="section"><i class="menu-item-icon fa fa-fw fa-home"></i><br>首页</a></li><li class="menu-item menu-item-tags"><a href="/tags/" rel="section"><i class="menu-item-icon fa fa-fw fa-tags"></i><br>标签</a></li><li class="menu-item menu-item-archives"><a href="/archives/" rel="section"><i class="menu-item-icon fa fa-fw fa-archive"></i><br>归档</a></li></ul></nav></div></header><main id="main" class="main"><div class="main-inner"><div class="content-wrap"><div id="content" class="content"><div id="posts" class="posts-expand"><article class="post post-type-normal" itemscope itemtype="http://schema.org/Article"><div class="post-block"><link itemprop="mainEntityOfPage" href="http://tinymd.github.io/post/8212f318.html"><span hidden itemprop="author" itemscope itemtype="http://schema.org/Person"><meta itemprop="name" content="tiny"><meta itemprop="description" content><meta itemprop="image" content="/images/avatar.gif"></span><span hidden itemprop="publisher" itemscope itemtype="http://schema.org/Organization"><meta itemprop="name" content="Tiny‘s blog"></span><header class="post-header"><h1 class="post-title" itemprop="name headline">Hands-on Machine Learning第二章</h1><div class="post-meta"><span class="post-time"><span class="post-meta-item-icon"><i class="fa fa-calendar-o"></i> </span><span class="post-meta-item-text">发表于</span> <time title="创建于" itemprop="dateCreated datePublished" datetime="2020-02-26T09:54:17+08:00">2020-02-26</time></span></div></header><div class="post-body" itemprop="articleBody"><a id="more"></a><h1 id="第二章-第一个完整的机器学习项目"><strong>第二章</strong> 第一个完整的机器学习项目</h1><blockquote><p>假设你是一个房地产公司的数据科学家，你的任务是使用加利福尼亚人口普查数据建立该州房价模型。该数据包括加利福尼亚州每个地区的人口，收入中位数和房价中位数等指标。模型应该从这些数据中学习，并能够根据所有其他指标来预测任何地区的房价中位数。</p></blockquote><p>完成一机器学习项目一般包含八个步骤：</p><ol type="1"><li>分析问题，问题的输入输出</li><li>准备数据</li><li>探索数据获得想法</li><li>准备数据以更好地将潜在数据模式暴露给机器学习算法</li><li>探索许多不同的模型，并列出最佳模型</li><li>微调模型</li><li>呈上解决方案</li><li>发布，监控并维护系统模型</li></ol><h1 id="分析问题">1、分析问题</h1><h2 id="明确问题价值并分类问题">1.1、明确问题价值并分类问题</h2><p>首先明确事情的价值，公司需要模型的商业目标是什么？是否值得投入时间？是否确确实实是房价中位数具体数值需要被使用到，而不是各种类别值如“便宜”“贵”等。</p><p>然后弄清当前对于此问题的解决办法，假设当前方法是由专家收集最新数据然后评估计算得到房价中位数。这种办法既耗时又耗力，因此此模型是很有价值的。</p><p>弄清模型是有价值后，你才投入设计系统模型。首先需要分类该机器学习问题，这是一个监督学习中的回归问题，用批处理学习能够很好解决。</p><h2 id="选择一个性能评估指标">1.2、选择一个性能评估指标</h2><p>回归问题典型的评估指标是均方根差。<span class="math inline">\(RMSE(X,h)=\sqrt{\frac{1}{m}\sum_{i=1}^{m}(h(x^{(i)})-y^{(i)})^2}\)</span>。衡量预测值与实际值之间距离的有许多种方式，统称为范式，范式指数越大，对大误差越敏感，会更加忽视小误差。</p><h1 id="准备数据">2、准备数据</h1><h2 id="下载并加载数据">2.1、下载并加载数据</h2><p>自动化获取数据的过程：如果数据频繁更新，写一个函数来下载数据是很有用的，你可以写一个脚本来调用函数获取最新数据。详细代码如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br></pre></td><td class="code"><pre><span class="line">import os</span><br><span class="line">import tarfile</span><br><span class="line">import urllib</span><br><span class="line"></span><br><span class="line">DOWNLOAD_ROOT = &quot;https://raw.githubusercontent.com/ageron/handson-ml2/master/&quot;</span><br><span class="line">HOUSING_PATH = os.path.join(&quot;datasets&quot;, &quot;housing&quot;)</span><br><span class="line">HOUSING_URL = DOWNLOAD_ROOT + &quot;datasets/housing/housing.tgz&quot;</span><br><span class="line"></span><br><span class="line">def fetch_housing_data(housing_url=HOUSING_URL, housing_path=HOUSING_PATH):</span><br><span class="line">    if not os.path.isdir(housing_path):</span><br><span class="line">        os.makedirs(housing_path)</span><br><span class="line">    tgz_path = os.path.join(housing_path, &quot;housing.tgz&quot;)</span><br><span class="line">    urllib.request.urlretrieve(housing_url, tgz_path)#第二个参数为文件名</span><br><span class="line">    housing_tgz = tarfile.open(tgz_path)</span><br><span class="line">    housing_tgz.extractall(path=housing_path)</span><br><span class="line">    housing_tgz.close()</span><br></pre></td></tr></table></figure><p>注意：</p><ol type="1"><li><p>这种直接网页访问的链接&quot;https://github.com/ageron/handson-ml/&quot;是存在问题的。且从github上下载东西如果不翻墙，会出现强迫关闭连接的情况。</p></li><li>每次下载时如果文件夹中带有同名文件则同名文件会被覆盖，解压时同样。</li><li><p>tarfile包无法解压zip文件，可用zipfile</p></li></ol><p>加载数据详细代码如下:</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">import pandas as pd</span><br><span class="line"></span><br><span class="line">def load_housing_data(housing_path=HOUSING_PATH):</span><br><span class="line">    csv_path = os.path.join(housing_path, &quot;housing.csv&quot;)</span><br><span class="line">    return pd.read_csv(csv_path)</span><br></pre></td></tr></table></figure><h2 id="研究数据的结构">2.2、研究数据的结构</h2><p>有几个函数方便我们了解数据的结构:</p><table><thead><tr class="header"><th>函数</th><th>作用</th></tr></thead><tbody><tr class="odd"><td>dataframe.head()</td><td>默认返回前5行数据</td></tr><tr class="even"><td>dataframe.info()</td><td>得到dataframe的简短描述，包括行数，列数，各列的非空值个数</td></tr><tr class="odd"><td>Series.value_counts()</td><td>得到series中各个不同取值的计数</td></tr><tr class="even"><td>dataframe.describe()</td><td>得到各个数值型特征的取值范围，分散程度</td></tr><tr class="odd"><td>dataframe.hist()</td><td>得到各个数值型特征的频率直方图</td></tr></tbody></table><p>dataframe.head()得到如下图所示：</p><p><img src="https://myblogdata-1300038172.cos.ap-shanghai.myqcloud.com/images/hands_on_ml_tf/2_1.png"></p><p>利用dataframe.info()得到如下图所示：</p><p><img src="https://myblogdata-1300038172.cos.ap-shanghai.myqcloud.com/images/hands_on_ml_tf/2_2.png"></p><p>我们可以看到：总共又20640个地区实例，每个地区有10个特征，其中''total_bedrooms&quot;这个特征存在缺失值，且除开'ocean_proximity'这个特征外，其他特征取值均为数值，由上面head()返回的信息我们可以看出'ocean_proximity'取值重复，因此我们猜测其为一个类别特征。</p><p>利用housing['ocean_proximity'].value_counts()得到如下图所示：</p><p><img src="https://myblogdata-1300038172.cos.ap-shanghai.myqcloud.com/images/hands_on_ml_tf/2_3.png"></p><p>研究其他所有的数值型特征，利用housing.describe()你可以了解各个数值型特征的取值范围，分散程度，如下图所示：</p><p><img src="https://myblogdata-1300038172.cos.ap-shanghai.myqcloud.com/images/hands_on_ml_tf/2_4.png"></p><p>仔细观察，</p><ol type="1"><li>显然各个特征取值范围不同，为便于使用机器学习算法，需要进行特征缩放，</li><li>‘median_income’单位不是$美元，且‘median_income’和'median_house_value'应该都被放缩了,'median_income'大概需要放大一万倍（不了解北美的房价）。</li></ol><p>如果你从这些统计中仍然不能很好理解数据，你可以为每一数值型特征画一频率直方图。housing.hist(bins=50)得到如下图所示：</p><p><img src="https://myblogdata-1300038172.cos.ap-shanghai.myqcloud.com/images/hands_on_ml_tf/2_5.png"></p><p>从这个直方图中我们可以知道一下几点：</p><ol type="1"><li>'housing_median_age','median_house_value'同样被放缩了，'median_house_value'被放缩是个较严重的问题，因为这是我们需要预测的值，对于此，我们需要详细了解这个的放缩规则，假设只是单纯的限制了最大值，我们可以采取以下两种措施：1）为被限制的所有地区找到所有真实的房价中位数 2）将所有被限制的地区实例从数据集中删除。</li><li>大部分频率直方图tail-heavy，可计算log。</li></ol><h2 id="构建测试数据集">2.3、构建测试数据集</h2><p>随机选取数据集中的20%作为测试数据集。第一种办法：可以自己写一个函数，为了既随机划分，又固定每一次生成的测试数据集，可以在生成随机数之前设定种子；第二种办法：利用Sklearn自带的划分函数train_test_split()，有random_state这一参数。</p><p>目前为止，我们都是完全随机的划分数据集，通常这种方式在你的数据集很大（相比于特征个数）时候是适用的，但是如果数据集大小一般的话，你就有可能面临采样偏差的风险，为保证测试集中各个种类的数据数量百分比与整个数据集中相符，我们采用<strong>分层抽样</strong>。</p><p>为保证你的测试数据集同样具有代表性，你首先得弄清楚什么特征对你的预测结果影响最大，假设你跟专家说收入中位数是个对于房价中位数及其重要的因素，那你需要确保测试集可以代表整个数据集中的各种收入类别。但收入中位数是个连续数值型变量，你需要先创建一个收入类别属性。那么具体分为哪几类？观察上图与上表，为保证每一类的数据量充足，我们可以讲收入类别分为5类，[0,1.5],[1.5,3],[3,4.5],[4.5,6],[6,inf]。用pd.cut函数能够快速实现将值分成离散间隔，具体代码如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">housing[&quot;income_cat&quot;] = pd.cut(housing[&quot;median_income&quot;],</span><br><span class="line">                               bins=[0., 1.5, 3.0, 4.5, 6., np.inf],</span><br><span class="line">                               labels=[1, 2, 3, 4, 5])</span><br></pre></td></tr></table></figure><p>然后用housing[&quot;income_cat&quot;].value_counts()和housing[&quot;income_cat&quot;].hist()验证一下如何分类是否合理。</p><p>之后你便可以开始准备分层抽样了，利用sklearn中的StratifiedShuffleSplit类，详细代码如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.model_selection import StratifiedShuffleSplit</span><br><span class="line"></span><br><span class="line">split = StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)#n_splits是将训练数据分成train/test对的组数，split函数返回两个ndarray,分别是训练集和测试集的索引</span><br><span class="line">for train_index, test_index in split.split(housing, housing[&quot;income_cat&quot;]):</span><br><span class="line">    strat_train_set = housing.loc[train_index]</span><br><span class="line">    strat_test_set = housing.loc[test_index]</span><br></pre></td></tr></table></figure><p>然后删除收入类别属性那一列，详细代码如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">for set_ in (strat_train_set,strat_test_set):</span><br><span class="line">	set_.drop(&apos;income_cat&apos;,axis=1,inplace=True)</span><br></pre></td></tr></table></figure><p>存在另一问题：当数据集更新时，我们不希望之前在训练集的数据变成测试集中的数据，可以采用hash值的办法crc32。我们可以将所有类别分开，然后对于每一类别选取同样百分比的测试集，并采用hash值的办法使得之前训练集的数据不会变成测试集的数据，我认为要固定测试集数据主要是为了对比各个机器学习算法的优劣。</p><h1 id="探索数据以获得想法">3、探索数据以获得想法</h1><p>到目前为止，你有了训练集和测试集，为了了解具体需要构造怎样的特征用于机器学习，你需要对训练数据进行更多探索，首先copy一份训练数据，以免探索过程中损坏。<code>housing=strat_train_set.copy()</code></p><p>既然这是一份关于地理位置的数据，那么我们先画出它的地理位置图。</p><h2 id="可视化地理数据">3.1、可视化地理数据</h2><p>设置数据点透明来观察数据点的密集度，代码如下：<code>housing.plot(kind=&quot;scatter&quot;, x=&quot;longitude&quot;, y=&quot;latitude&quot;, alpha=0.1)</code>，得到如下图所示：</p><p><img src="https://myblogdata-1300038172.cos.ap-shanghai.myqcloud.com/images/hands_on_ml_tf/2_6.png"></p><p>至此可以推测一下，那么密集点所在区域大部分沿海，应该是人口较为密集的地方，那么应该也是房价相对较高的地方。如果对房价与沿海距离和人口数量间的关系依旧存有疑虑，可以用colormap画一个价格的热度图，用人口表示数据点的大小。代码为<code>housing.plot(kind=&quot;scatter&quot;, x=&quot;longitude&quot;, y=&quot;latitude&quot;, alpha=0.4,s=housing[&quot;population&quot;]/100, label=&quot;population&quot;, figsize=(10,7),c=&quot;median_house_value&quot;, cmap=plt.get_cmap(&quot;jet&quot;), colorbar=True,sharex=False)</code>，得到下图所示：</p><p><img src="https://myblogdata-1300038172.cos.ap-shanghai.myqcloud.com/images/hands_on_ml_tf/2_7.png"></p><p>我们很容易猜测出房价应当与人口和沿海距离有关系，但似乎规则较为复杂（有些人口多，密度低，沿海近的地区房价低）。因此我们先简单尝试计算一下各个特征与房价间的相关系数，并看看各个特征之间又有什么相关性。</p><h2 id="寻找特征间的相关性">3.2、寻找特征间的相关性</h2><p>dataframe自带一个计算各个属性间线性相关系数的函数corr()，详细代码如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">corr_matrix = housing.corr()</span><br><span class="line">corr_matrix[&quot;median_house_value&quot;].sort_values(ascending=False)</span><br></pre></td></tr></table></figure><p>得到如下图所示：</p><p><img src="https://myblogdata-1300038172.cos.ap-shanghai.myqcloud.com/images/hands_on_ml_tf/2_8.png"></p><p>corr()可以得到两者之间的线性相关程度，可以看到收入与房价之间有很强的正相关性，但corr()会忽略掉很多非线性关系，为此，我们可以利用scatter_matrix()将任意两个属性间的关系图画出来，总共有10个特征：经度、纬度、房屋年龄、房间数、卧室数、人口、家庭数、收入、近海程度、房价。两两关系都画出来太多图，因此我们选择应该应该与房价关系最大的3个特征：房屋年龄、房间数、收入。（除开书上，我们单独画出了人口与房价的散点图，两者同样感觉没有啥直接关系）。详细代码如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">from pandas.plotting import scatter_matrix</span><br><span class="line">attributes = [&quot;median_house_value&quot;, &quot;median_income&quot;, &quot;total_rooms&quot;,</span><br><span class="line">              &quot;housing_median_age&quot;]</span><br><span class="line">scatter_matrix(housing[attributes], figsize=(12, 8))</span><br></pre></td></tr></table></figure><p>得到下图：</p><p><img src="https://myblogdata-1300038172.cos.ap-shanghai.myqcloud.com/images/hands_on_ml_tf/2_9.png"></p><p>emmmmmmm把散点图画出来依旧感觉只有收入与房价存在相关性。把这两者的关系单独画出来放大一下，<code>housing.plot(kind=&quot;scatter&quot;, x=&quot;median_income&quot;, y=&quot;median_house_value&quot;,alpha=0.1)</code>，得到下图：</p><p><img src="https://myblogdata-1300038172.cos.ap-shanghai.myqcloud.com/images/hands_on_ml_tf/2_10.png"></p><p>从上图可看出两点：</p><ol type="1"><li>收入与房价间存在很强的正相关性</li><li>最顶上有一条横线，应该是超过的数据被限制了上限，这属于数据的错误，我们要不修正要不移除。</li></ol><p>emmmm到这里我们画了很多图，但我们并没有得到比一开始多很多的认识，但这些图都是有必要的，我们得先画出来才能判断到底有没有其他的关系。总结一下我们得到的就是以上两点。</p><p>到目前为止，我们研究了各个不同属性数据的本身结构，如是否是数字，是否被限制了，是否存在缺失值，接着划分了训练集和测试集，然后研究特征与预测值之间的相关性，到给数据应用机器学习算法之前，我们还需要尝试各种属性组合。</p><h2 id="尝试各种属性组合">3.3、尝试各种属性组合</h2><p>书上简单的尝试了几种组合，如房间数除以人口数，卧室数除以房间数，人数除以家庭数，并计算了新的组合特征与预测值的相关性。</p><p><strong>注意：书上所有的探索数据过程都是在给你提供一个大概思路，事实并没有对被限制的数据进行处理</strong></p><h1 id="准备机器学习的数据">4、准备机器学习的数据</h1><p>分开训练数据与其label。代码如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">housing = strat_train_set.drop(&quot;median_house_value&quot;, axis=1) </span><br><span class="line">housing_labels = strat_train_set[&quot;median_house_value&quot;].copy()</span><br></pre></td></tr></table></figure><h2 id="数据清洗-缺失值">4.1、数据清洗-缺失值</h2><p>从前面我们知道'total_bedrooms'这个属性存在缺失值，我们有三个选择，扔掉对应的区，扔掉这整个属性，填补对应的值，可以分别使用dataframe的dropna()，drop()，和fillna()。</p><p>除此之外，sklearn针对缺失值的问题设计了一个类:SimpleImputer。</p><p>在讲这个之前，先说明一下Sklearn设定了两种比较特别的类：评估器(Estimator)和转换器(Transformer)。可以根据数据集估算某些参数的任何类称为评估器，估算操作由fit()方法完成；那些同样还能转换数据集的评估器称为转换器，转换操作由transform()方法。</p><p>继续讲SimpleImputer，使用方法如下，首先初始化实例，并指定填补策略。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.impute import SimpleImputer</span><br><span class="line">imputer = SimpleImputer(strategy=&quot;median&quot;)</span><br></pre></td></tr></table></figure><p>由于只有数值才有中位数，因此需要先扔掉非数值型属性'ocean_proximity'。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br></pre></td><td class="code"><pre><span class="line">housing_num = housing.drop(&quot;ocean_proximity&quot;, axis=1)</span><br><span class="line">imputer.fit(housing_num)</span><br></pre></td></tr></table></figure><p>评估的结果存储在statistics_变量中，可用<code>imputer.statistics_</code>访问。然后你可以用transform方法转换数据集，<code>X = imputer.transform(housing_num)</code>，返回的X是一个numpy的array，你可以将其转换为dataframe，<code>housing_tr = pd.DataFrame(X, columns=housing_num.columns, index=housing_num.index)</code>。</p><h2 id="处理文本和分类属性">4.2、处理文本和分类属性</h2><p>我们由前面知道'ocean_proximity'这个属性是一个类别属性，机器学习算法更能方便处理数字，因此我们将其全部转换为数字，可以使用OrdinalEncoder。这既是一个评估器也是一个转换器，具体代码如下：</p><p>首先单独取出该类别<code>housing_cat=housing[[&quot;ocean_proximity&quot;]]</code>，注意这样子取返回的仍然是个dataframe。然后转换：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.preprocessing import OrdinalEncoder</span><br><span class="line">ordinal_encoder = OrdinalEncoder()</span><br><span class="line">housing_cat_encoded = ordinal_encoder.fit_transform(housing_cat)</span><br></pre></td></tr></table></figure><p>但机器学习算法往往会认为邻近的数字更相近，但此处类别明显不适用这一特性，因此我们采用one-hot编码，使用OneHotEncoder()。具体代码如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.preprocessing import OneHotEncoder</span><br><span class="line">cat_encoder = OneHotEncoder()</span><br><span class="line">housing_cat_1hot = cat_encoder.fit_transform(housing_cat)</span><br></pre></td></tr></table></figure><p>默认情况下，OneHotEncoder会返回一个稀疏矩阵（因为0较多），但可以调用toarray方法转换成Numpy的array。</p><h2 id="定制转换器">4.3、定制转换器</h2><p>sklearn提供了很多转换器使得操作方便快捷，你也可以自己编写transformer，你只需要创建一个类，实现三个方法:fit(), transform(), fit_transform()。获得fit_transform()这个方法只需要增加TransformerMixin作为基类，把之前的属性组合写成一个transfomer，具体代码如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.base import BaseEstimator, TransformerMixin</span><br><span class="line"></span><br><span class="line"># column index</span><br><span class="line">rooms_ix, bedrooms_ix, population_ix, households_ix = 3, 4, 5, 6</span><br><span class="line"></span><br><span class="line">class CombinedAttributesAdder(BaseEstimator, TransformerMixin):</span><br><span class="line">    def __init__(self, add_bedrooms_per_room = True): # no *args or **kargs</span><br><span class="line">        self.add_bedrooms_per_room = add_bedrooms_per_room</span><br><span class="line">    def fit(self, X, y=None):</span><br><span class="line">        return self  # nothing else to do</span><br><span class="line">    def transform(self, X):</span><br><span class="line">        rooms_per_household = X[:, rooms_ix] / X[:, households_ix]</span><br><span class="line">        population_per_household = X[:, population_ix] / X[:, households_ix]</span><br><span class="line">        if self.add_bedrooms_per_room:</span><br><span class="line">            bedrooms_per_room = X[:, bedrooms_ix] / X[:, rooms_ix]</span><br><span class="line">            return np.c_[X, rooms_per_household, population_per_household,</span><br><span class="line">                         bedrooms_per_room]</span><br><span class="line">        else:</span><br><span class="line">            return np.c_[X, rooms_per_household, population_per_household]</span><br><span class="line"></span><br><span class="line">attr_adder = CombinedAttributesAdder(add_bedrooms_per_room=False)</span><br><span class="line">housing_extra_attribs = attr_adder.transform(housing.values)</span><br></pre></td></tr></table></figure><h2 id="特征缩放">4.4、 特征缩放</h2><p>sklearn提供了两种方法进行特征缩放：</p><ol type="1"><li>MinMaxScaler，（待处理值-最小值）/（最大值-最小值）</li><li>StandardScaler，（待处理值-均值）/（标准差）</li></ol><h2 id="编写管道">4.5 、编写管道</h2><p>我们可以看到有许多数据转换过程需要顺序完成，sklearn提供了Pipeline来帮助完成序列化的数据转换，我们前面对数字特征进行了缺失值处理，属性组合，特征缩放。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.pipeline import Pipeline</span><br><span class="line">from sklearn.preprocessing import StandardScaler</span><br><span class="line"></span><br><span class="line">num_pipeline = Pipeline([</span><br><span class="line">        (&apos;imputer&apos;, SimpleImputer(strategy=&quot;median&quot;)),</span><br><span class="line">        (&apos;attribs_adder&apos;, CombinedAttributesAdder()),</span><br><span class="line">        (&apos;std_scaler&apos;, StandardScaler()),</span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line">housing_num_tr = num_pipeline.fit_transform(housing_num)</span><br></pre></td></tr></table></figure><p>我们为数字特征编写了管道，还剩下类别特征是单独处理的，如果我们能一次性转换所有列，这将会更加方便，sklearn的ColumnTransformer提供了解决办法。具体代码如下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.compose import ColumnTransformer</span><br><span class="line"></span><br><span class="line">num_attribs = list(housing_num)</span><br><span class="line">cat_attribs = [&quot;ocean_proximity&quot;]</span><br><span class="line"></span><br><span class="line">full_pipeline = ColumnTransformer([</span><br><span class="line">        (&quot;num&quot;, num_pipeline, num_attribs),</span><br><span class="line">        (&quot;cat&quot;, OneHotEncoder(), cat_attribs),</span><br><span class="line">    ])</span><br><span class="line"></span><br><span class="line">housing_prepared = full_pipeline.fit_transform(housing)</span><br></pre></td></tr></table></figure><p>我们首先获取数字特征名字的列表和类别特征名字特征的列表，然后构造ColumnTransformer，它需要list of tuples，每一tuple由名字，转换器和应用该转换器的列名字列表组成。</p><p>到目前为止，你已经分析好了问题，准备并探索了数据，将数据划分为了训练和测试数据集，且写好了用来自动化清洗转换数据的pipeline。你现在应该选择一个机器学习模型并开始训练了。</p><h1 id="选择并训练模型">5、选择并训练模型</h1><h2 id="在训练集上训练并评估">5.1、在训练集上训练并评估</h2><p>首先随意套用一个线性回归的模型，来尝试一下：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.linear_model import LinearRegression</span><br><span class="line"></span><br><span class="line">lin_reg = LinearRegression()</span><br><span class="line">lin_reg.fit(housing_prepared, housing_labels)</span><br></pre></td></tr></table></figure><p>好哒，已经训练好了，取训练集前5个数据预测一下，</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">some_data = housing.iloc[:5]</span><br><span class="line">some_labels = housing_labels.iloc[:5]</span><br><span class="line">some_data_prepared = full_pipeline.transform(some_data)</span><br><span class="line">print(&quot;Predictions:&quot;, lin_reg.predict(some_data_prepared))</span><br><span class="line">print(&quot;Labels:&quot;, list(some_labels))</span><br></pre></td></tr></table></figure><p>然后我们可以评估在训练集上的误差：</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.metrics import mean_squared_error</span><br><span class="line"></span><br><span class="line">housing_predictions = lin_reg.predict(housing_prepared)</span><br><span class="line">lin_mse = mean_squared_error(housing_labels, housing_predictions)</span><br><span class="line">lin_rmse = np.sqrt(lin_mse)</span><br></pre></td></tr></table></figure><p>结果为$68,628，显然这个结果不是太好，模型应该是欠拟合的，这种情况发生应该是由于特征提供的信息不够不便做出预测或模型不够强大。我们针对欠拟合有三种方法：一是选择一个更强大的模型，二是构造更多的特征用于训练，三是减少模型的限制。因为我们这里并没有正则化限制参数，因此我们只有前两种操作方法，你可以构造更多特征(如log(population))，此处我们先尝试更复杂的模型。</p><p>尝试一下决策树模型，DecisionTreeRegressor()。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.tree import DecisionTreeRegressor</span><br><span class="line"></span><br><span class="line">tree_reg = DecisionTreeRegressor(random_state=42)</span><br><span class="line">tree_reg.fit(housing_prepared, housing_labels)</span><br></pre></td></tr></table></figure><p>将训练数据fit进决策树模型，然后再评估训练好的模型在训练集上的误差，神奇般发现为0，显然这就是过拟合了，我们无法完全确定，我们还需要数据去衡量，但正如我们之前讨论的，测试数据得直到系统发布前才用于计算泛化误差，因此为前期的模型选择，我们将训练集划分为训练集和验证集。</p><h2 id="交叉验证评估模型">5.2、交叉验证评估模型</h2><p>当你想确定使用哪一类模型训练最为有效时，你需要从训练集中分开验证集验证，你可以像之前一样运用train_test_split()划分训练集和验证集，一个更好的办法是使用sklearn自带的k折交叉验证。</p><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">from sklearn.model_selection import cross_val_score</span><br><span class="line"></span><br><span class="line">scores = cross_val_score(tree_reg, housing_prepared, housing_labels,</span><br><span class="line">                         scoring=&quot;neg_mean_squared_error&quot;, cv=10)</span><br><span class="line">tree_rmse_scores = np.sqrt(-scores)</span><br></pre></td></tr></table></figure><p>得到决策树模型交叉验证的结果，对线性回归同样采取交叉验证，最后发现决策树过拟合导致它比线性回归的效果还要差。我们再尝试一下另一个模型随机森林，集成学习的一种，sklearn中为RandomForestRegressor。你不断的尝试很多的模型，目的是筛选出学习效果较好的模型。</p><h1 id="模型调参">6、模型调参</h1><p>假设你现在已经有了效果较好模型的一个小列表，对于模型的超参数调节。<strong>这一部分等到后面再补上，涉及到超参数的含义等</strong></p></div><footer class="post-footer"><div class="post-tags"><a href="/tags/书本总结/" rel="tag"># 书本总结</a> <a href="/tags/机器学习/" rel="tag"># 机器学习</a></div><div class="post-nav"><div class="post-nav-next post-nav-item"><a href="/post/cb5a82e8.html" rel="next" title="Hands on Machine Learning 第一章"><i class="fa fa-chevron-left"></i> Hands on Machine Learning 第一章</a></div><span class="post-nav-divider"></span><div class="post-nav-prev post-nav-item"><a href="/post/cf0c504a.html" rel="prev" title="Hands-on Machine Learning第三章">Hands-on Machine Learning第三章 <i class="fa fa-chevron-right"></i></a></div></div></footer></div></article><div class="post-spread"></div></div></div></div><div class="sidebar-toggle"><div class="sidebar-toggle-line-wrap"><span class="sidebar-toggle-line sidebar-toggle-line-first"></span> <span class="sidebar-toggle-line sidebar-toggle-line-middle"></span> <span class="sidebar-toggle-line sidebar-toggle-line-last"></span></div></div><aside id="sidebar" class="sidebar"><div class="sidebar-inner"><ul class="sidebar-nav motion-element"><li class="sidebar-nav-toc sidebar-nav-active" data-target="post-toc-wrap">文章目录</li><li class="sidebar-nav-overview" data-target="site-overview-wrap">站点概览</li></ul><section class="site-overview-wrap sidebar-panel"><div class="site-overview"><div class="site-author motion-element" itemprop="author" itemscope itemtype="http://schema.org/Person"><p class="site-author-name" itemprop="name">tiny</p><p class="site-description motion-element" itemprop="description"></p></div><nav class="site-state motion-element"><div class="site-state-item site-state-posts"><a href="/archives/"><span class="site-state-item-count">9</span> <span class="site-state-item-name">日志</span></a></div><div class="site-state-item site-state-tags"><a href="/tags/index.html"><span class="site-state-item-count">5</span> <span class="site-state-item-name">标签</span></a></div></nav></div></section><section class="post-toc-wrap motion-element sidebar-panel sidebar-panel-active"><div class="post-toc"><div class="post-toc-content"><ol class="nav"><li class="nav-item nav-level-1"><a class="nav-link" href="#第二章-第一个完整的机器学习项目"><span class="nav-text">第二章 第一个完整的机器学习项目</span></a></li><li class="nav-item nav-level-1"><a class="nav-link" href="#分析问题"><span class="nav-text">1、分析问题</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#明确问题价值并分类问题"><span class="nav-text">1.1、明确问题价值并分类问题</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#选择一个性能评估指标"><span class="nav-text">1.2、选择一个性能评估指标</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#准备数据"><span class="nav-text">2、准备数据</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#下载并加载数据"><span class="nav-text">2.1、下载并加载数据</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#研究数据的结构"><span class="nav-text">2.2、研究数据的结构</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#构建测试数据集"><span class="nav-text">2.3、构建测试数据集</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#探索数据以获得想法"><span class="nav-text">3、探索数据以获得想法</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#可视化地理数据"><span class="nav-text">3.1、可视化地理数据</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#寻找特征间的相关性"><span class="nav-text">3.2、寻找特征间的相关性</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#尝试各种属性组合"><span class="nav-text">3.3、尝试各种属性组合</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#准备机器学习的数据"><span class="nav-text">4、准备机器学习的数据</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#数据清洗-缺失值"><span class="nav-text">4.1、数据清洗-缺失值</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#处理文本和分类属性"><span class="nav-text">4.2、处理文本和分类属性</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#定制转换器"><span class="nav-text">4.3、定制转换器</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#特征缩放"><span class="nav-text">4.4、 特征缩放</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#编写管道"><span class="nav-text">4.5 、编写管道</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#选择并训练模型"><span class="nav-text">5、选择并训练模型</span></a><ol class="nav-child"><li class="nav-item nav-level-2"><a class="nav-link" href="#在训练集上训练并评估"><span class="nav-text">5.1、在训练集上训练并评估</span></a></li><li class="nav-item nav-level-2"><a class="nav-link" href="#交叉验证评估模型"><span class="nav-text">5.2、交叉验证评估模型</span></a></li></ol></li><li class="nav-item nav-level-1"><a class="nav-link" href="#模型调参"><span class="nav-text">6、模型调参</span></a></li></ol></div></div></section></div></aside></div></main><footer id="footer" class="footer"><div class="footer-inner"><div class="copyright">&copy; <span itemprop="copyrightYear">2020</span> <span class="with-love"><i class="fa fa-user"></i> </span><span class="author" itemprop="copyrightHolder">tiny</span></div><div class="powered-by">由 <a class="theme-link" target="_blank" href="https://hexo.io">Hexo</a> 强力驱动</div><span class="post-meta-divider">|</span><div class="theme-info">主题 &mdash; <a class="theme-link" target="_blank" href="https://github.com/iissnan/hexo-theme-next">NexT.Gemini</a> v5.1.4</div></div></footer><div class="back-to-top"><i class="fa fa-arrow-up"></i></div></div><script type="text/javascript">"[object Function]"!==Object.prototype.toString.call(window.Promise)&&(window.Promise=null)</script><script type="text/javascript" src="/lib/jquery/index.js?v=2.1.3"></script><script type="text/javascript" src="/lib/fastclick/lib/fastclick.min.js?v=1.0.6"></script><script type="text/javascript" src="/lib/jquery_lazyload/jquery.lazyload.js?v=1.9.7"></script><script type="text/javascript" src="/lib/velocity/velocity.min.js?v=1.2.1"></script><script type="text/javascript" src="/lib/velocity/velocity.ui.min.js?v=1.2.1"></script><script type="text/javascript" src="/lib/fancybox/source/jquery.fancybox.pack.js?v=2.1.5"></script><script type="text/javascript" src="/js/src/utils.js?v=5.1.4"></script><script type="text/javascript" src="/js/src/motion.js?v=5.1.4"></script><script type="text/javascript" src="/js/src/affix.js?v=5.1.4"></script><script type="text/javascript" src="/js/src/schemes/pisces.js?v=5.1.4"></script><script type="text/javascript" src="/js/src/scrollspy.js?v=5.1.4"></script><script type="text/javascript" src="/js/src/post-details.js?v=5.1.4"></script><script type="text/javascript" src="/js/src/bootstrap.js?v=5.1.4"></script><script type="text/x-mathjax-config">MathJax.Hub.Config({
        tex2jax: {
          inlineMath: [ ['$','$'], ["\\(","\\)"]  ],
          processEscapes: true,
          skipTags: ['script', 'noscript', 'style', 'textarea', 'pre', 'code']
        }
      });</script><script type="text/x-mathjax-config">MathJax.Hub.Queue(function() {
        var all = MathJax.Hub.getAllJax(), i;
        for (i=0; i < all.length; i += 1) {
          all[i].SourceElement().parentNode.className += ' has-jax';
        }
      });</script><script type="text/javascript" src="//cdn.bootcss.com/mathjax/2.7.1/latest.js?config=TeX-AMS-MML_HTMLorMML"></script></body></html>